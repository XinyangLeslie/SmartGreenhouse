//
//  SpeechRecognizer.swift
//  XinyangTestApp
//
//  Created by å¼ æ–°æ¨ on 2025/3/17.
//

import Foundation
import Speech
import AVFoundation

class SpeechRecognizer: ObservableObject {
    @Published var recognizedText: String = ""  // å­˜å‚¨è¯†åˆ«çš„æ–‡æœ¬

    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "zh-CN"))  // è®¾ç½®ä¸ºä¸­æ–‡
    private let audioEngine = AVAudioEngine()
    private let request = SFSpeechAudioBufferRecognitionRequest()
    private var recognitionTask: SFSpeechRecognitionTask?

    init() {
        requestAuthorization()  // ç”³è¯·æƒé™
    }

    

    func requestMicrophonePermission() {
        AVAudioSession.sharedInstance().requestRecordPermission { granted in
            if granted {
                print("âœ… éº¦å…‹é£æƒé™å·²æˆæƒ")
            } else {
                print("âŒ ç”¨æˆ·æ‹’ç»äº†éº¦å…‹é£æƒé™")
            }
        }
    }

    
    /// ç”³è¯·è¯­éŸ³è¯†åˆ«æƒé™
    private func requestAuthorization() {
        SFSpeechRecognizer.requestAuthorization { status in
            DispatchQueue.main.async {
                switch status {
                case .authorized:
                    print("âœ… è¯­éŸ³è¯†åˆ«æƒé™å·²æˆæƒ")
                case .denied, .restricted, .notDetermined:
                    print("âŒ è¯­éŸ³è¯†åˆ«æƒé™è¢«æ‹’ç»æˆ–æœªè®¾ç½®")
                @unknown default:
                    fatalError()
                }
            }
        }
    }

    /// å¼€å§‹è¯­éŸ³è¯†åˆ«
    func startListening() {
        do {
            let inputNode = audioEngine.inputNode
            let recognitionFormat = inputNode.outputFormat(forBus: 0)
            inputNode.installTap(onBus: 0, bufferSize: 1024, format: recognitionFormat) { (buffer, _) in
                self.request.append(buffer)
            }
            
            audioEngine.prepare()
            try audioEngine.start()
            
            recognitionTask = speechRecognizer?.recognitionTask(with: request) { result, error in
                if let result = result {
                    DispatchQueue.main.async {
                        self.recognizedText = result.bestTranscription.formattedString
                        print("ğŸ™ï¸ è¯†åˆ«åˆ°æ–‡æœ¬: \(self.recognizedText)")
                    }
                }
                if error != nil {
                    self.stopListening()
                }
            }
        } catch {
            print("âŒ è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥: \(error.localizedDescription)")
        }
    }

    /// åœæ­¢è¯­éŸ³è¯†åˆ«
    func stopListening() {
        audioEngine.stop()
        recognitionTask?.cancel()
        recognitionTask = nil
        print("ğŸ›‘ è¯­éŸ³è¯†åˆ«å·²åœæ­¢")
    }
}
